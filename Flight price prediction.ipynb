{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfce10a4",
   "metadata": {},
   "source": [
    "# Problem Statement - \n",
    "\n",
    "Anyone who has booked a flight ticket knows how unexpectedly the prices vary. The cheapest available ticket on a given flight gets more and less expensive over time. This usually happens as\n",
    "an attempt to maximize revenue based on -\n",
    "\n",
    "\n",
    "1. Time of purchase patterns (making sure last-minute purchases are expensive)\n",
    "\n",
    "2. Keeping the flight as full as they want it (raising prices on a flight which is filling up in order to reduce sales and hold back inventory for those expensive last-minute expensive\n",
    "purchases)\n",
    "\n",
    "\n",
    "So, we have to work on a project where we collect data of flight fares with other features and work to make a model to predict fares of flights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c629b94",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc4a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To print all rows\n",
    "\n",
    "pd.set_option('display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e804bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "\n",
    "df = pd.read_csv(\"Flight_Price.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b2f556",
   "metadata": {},
   "source": [
    "Since Price is our target and it seems to be continuous feature so this perticular problem is Regression Problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b836c",
   "metadata": {},
   "source": [
    "### Features Information:\n",
    "    \n",
    "    \n",
    " - Airline: The name of the airline.\n",
    "    \n",
    " - Journey_date: The date of the journey.\n",
    "    \n",
    " - From: The source from which the service begins.\n",
    "    \n",
    " - To: The destination where the service ends.\n",
    "    \n",
    " - Route: The route taken by the flight to reach the destination.\n",
    "    \n",
    " - D_Time: The time when the journey starts from the source.\n",
    "    \n",
    " - A_Time: Time of arrival at the destination.\n",
    "    \n",
    " - Stops: Total stops between the source and destination.\n",
    "    \n",
    " - Price: The price of the ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d8a3a0",
   "metadata": {},
   "source": [
    "## Preprocessing and EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d692987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking shape of our dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef722558",
   "metadata": {},
   "source": [
    "In our dataset we have 5204 rows and 9 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c8d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Column \"Unnamed:0 as it will not affect our core dataset\n",
    "\n",
    "df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c601c65",
   "metadata": {},
   "source": [
    "Removing Unnamed: 0 column as it is the index column of csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd9c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing First row as it have only NaN values\n",
    "\n",
    "df=df.drop([df.index[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c798d9da",
   "metadata": {},
   "source": [
    "Since we are having all the entries in first row as nan so we have dropped this row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43eb696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Equalizing Price column\n",
    "\n",
    "df.Price = df.Price.str.replace('[^0-9.]','').astype('float64')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b137d4c",
   "metadata": {},
   "source": [
    "We have changed the price column datatype to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48182bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking all column names\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfade5c",
   "metadata": {},
   "source": [
    "Above are the column names of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b5abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the data types of all columns\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00772d04",
   "metadata": {},
   "source": [
    "Except Price all other columns are object type datas. But we have to convert journey_date, d_time and a_time columns from object to datetime type data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b029ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the info about the dataset\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7194d588",
   "metadata": {},
   "source": [
    "There is no nan values in the dataset. But we have to convert journey_date, d_time and a_time columns from object to datetime type data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4914be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check the value count of each column to see if there are any unexpected and unwanted entries present in the column.\n",
    "\n",
    "for i in df.columns:\n",
    "        print(df[i].value_counts())\n",
    "        print('****************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65368fa",
   "metadata": {},
   "source": [
    " - Above are the value counts of each column. In Airline and Stops column we have to use grouping to get better understanding on the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32fe3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping Airlines column for multiple airlines\n",
    "\n",
    "df[\"Airline\"].replace((\"Spicejet, IndiGo\",\"Air India, IndiGo\",\"Spicejet, AirAsia\",\"IndiGo, Air India\",\"IndiGo, Spicejet\",\"AirAsia, IndiGo\",\"IndiGo, Go First\",\"IndiGo, TruJet\",\"Vistara, IndiGo\",\"Spicejet, Air India\",\"Air India, Go First\",\"Vistara, Spicejet\",\"Spicejet, Go First\",\"Go First, IndiGo\",\"IndiGo, AirAsia\",\"Air India, AirAsia\",\"Vistara, Go First\",\"TruJet, IndiGo\",\"Spicejet, Vistara\",\"IndiGo, Vistara\",\"Air India, Spicejet\",\"AirAsia, Go First\",\"Vistara, AirAsia\",\"Vistara, Air India\",\"Go First, AirAsia\",\"Spicejet, TruJet\",\"Vistara, TruJet\",\"AirAsia, TruJet\",\"Go First, Air India\",\"Go First, Spicejet\",\"Air India, Vistara\"),\"Multiple Airlines\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a7964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the value counts of Airline column\n",
    "\n",
    "df.Airline.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9759f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping Stops column \n",
    "\n",
    "df[\"Stops\"].replace((\"1 stop via Mumbai\",\"1 stop via Hyderabad\",\"1 stop via Bengaluru\",\"1 stop via New Delhi\",\"1 stop via Ahmedabad\",\"1 stop via Goa\",\"1 stop via Pune\",\"1 stop via Lucknow\",\"1 stop via Ranchi\",\"1 stop via Kolkata\",\"1 stop via Chennai\",\"1 stop via Chandigarh\",\"1 stop via Kochi\",\"1 stop via Jaipur\",\"1 stop via Nagpur\",\"1 stop via Amritsar\",\"1 stop via Patna\",\"1 stop via Surat\",\"1 stop via Guwahati\",\"1 stop via Vadodara\",\"1 stop via Udaipur\",\"1 stop via Indore\",\"1 stop via Bhavnagar\",\"1 stop via Madurai\",\"1 stop via Bagdogra\",\"1 stop via Varanasi\",\"1 stop via Srinagar\",\"1 stop via Mangalore\",\"1 stop via Jammu\",\"1 stop via Vijayawada\",\"1 stop via Jodhpur\",\"1 stop via Kalaburagi\",\"1 stop via Aurangabad\",\"1 stop via Rajkot\",\"1 stop via Mysore\",\"1 stop via Bhopal\",\"1 stop via Tirupati\",\"1 stop via Dehradun\",\"1 stop via Visakhapatnam\"),\"1 Stop\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping Stops column\n",
    "\n",
    "df[\"Stops\"].replace((\"2 stop via New Delhi,Hyderabad\",\"2 stop via Hyderabad,New Delhi\",\"2 stop via Mumbai,Hyderabad\",\"2 stop via Mumbai,New Delhi\",\"2 stop via Hyderabad,Mumbai\",\"2 stop via Bengaluru,Hyderabad\",\"2 stop via Hyderabad,Bengaluru\",\"2 stop via New Delhi,Mumbai\",\"2 stop via Varanasi,Bengaluru\",\"2 stop via New Delhi,Chandigarh\",\"2 stop via Chandigarh,New Delhi\",\"2 stop via Chandigarh,Ahmedabad\",\"2 stop via Ranchi,New Delhi\",\"2 stop via Ranchi,Bengaluru\",\"2 stop via Ahmedabad,Chandigarh\",\"2 stop via Chandigarh,Srinagar\",\"2 stop via Bengaluru,Ranchi\",\"2 stop via Jammu,Srinagar\",\"2 stop via Kochi,Mumbai\",\"2 stop via New Delhi,Varanasi\",\"2 stop via Hyderabad,Mysore\",\"2 stop via Mumbai,Ranchi\",\"2 stop via Chennai,Ranchi\",\"2 stop via Hyderabad,Pune\",\"2 stop via Nagpur,Pune\",\"2 stop via Chennai,Hyderabad\",\"2 stop via Pune,Hyderabad\",\"2 stop via Hyderabad,Nanded\",\"2 stop via Vijayawada,Hyderabad\",\"2 stop via Hyderabad,Goa\",\"2 stop via Nanded,Hyderabad\",\"2 stop via Mumbai,Chandigarh\",\"2 stop via Belgaum,Hyderabad\",\"2 stop via Chennai,Jaipur\",\"2 stop via Hyderabad,Chennai\",\"2 stop via Hyderabad,Tirupati\",\"2 stop via Srinagar,Chandigarh\",\"2 stop via Mangalore,Mumbai\",\"2 stop via Amritsar,Srinagar\",\"2 stop via Goa,Hyderabad\",\"2 stop via Mysore,Hyderabad\"),\"2 Stops\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0437238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping Stops column\n",
    "\n",
    "df[\"Stops\"].replace((\"3 stop via Goa,New Delhi,Hyderabad\",\"3 stop via Mumbai,Aurangabad,New Delhi\",\"3 stop via Chandigarh,New Delhi,Ranchi\",\"3 stop via New Delhi,Aurangabad,Mumbai\",\"3 stop via Leh,Jammu,Srinagar\",\"3 stop via Bhubaneswar,New Delhi,Hyderabad\",\"3 stop via Hyderabad,New Delhi,Mumbai\",\"3 stop via Indore,Hyderabad,Mumbai\",\"3 stop via Hyderabad,New Delhi,Jaipur\",\"3 stop via Hyderabad,New Delhi,Goa\",\"3 stop via Ahmedabad,New Delhi,Hyderabad\",\"3 stop via Belgaum,Hyderabad,Mumbai\",\"3 stop via Hyderabad,New Delhi,Bhopal\",\"3 stop via Mumbai,New Delhi,Hyderabad\"),\"3 Stops\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e1b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping Stops column\n",
    "\n",
    "df[\"Stops\"].replace((\"4 stop via Bhubaneswar,Surat,New Delhi,Hyderabad\"),\"4 Stops\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the value counts of Stops column\n",
    "\n",
    "df.Stops.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e741e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let me assign values for Stops column\n",
    "\n",
    "df.replace({\"Non stop\": 0,\"1 Stop\": 1,\"2 Stops\": 2,\"3 Stops\": 3,\"4 Stops\": 4},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the value counts of Stops column again\n",
    "\n",
    "df.Stops.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e546f0",
   "metadata": {},
   "source": [
    " - Now Stops column is set for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e3e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking null values in Dataset\n",
    "\n",
    "print(\"Empty cells in Dataset is \",df.isna().values.any())\n",
    "\n",
    "print(\"\\nColumnwise Empty cell analysis\\n\")\n",
    "\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146cb5e6",
   "metadata": {},
   "source": [
    " - There are no null values in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5232e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizeing null values\n",
    "\n",
    "plt.figure(figsize=[12,4])\n",
    "\n",
    "sns.heatmap(df.isnull())\n",
    "\n",
    "plt.title(\"Null Values\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f546e72",
   "metadata": {},
   "source": [
    " - By visualization we can clearly say that there is no null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d4072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for empty observations\n",
    "\n",
    "df.loc[df['Price'] == \" \"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f8fd8",
   "metadata": {},
   "source": [
    " - There is no empty observations in our target column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd78a273",
   "metadata": {},
   "source": [
    "# Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a49ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting object data type to datetime in Journey_date column \n",
    "\n",
    "df['Journey_date'] =  pd.to_datetime(df['Journey_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb3c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Journey year,month and day from Journey_date\n",
    "\n",
    "#Extracting year\n",
    "df[\"Journey_year\"]=pd.to_datetime(df.Journey_date, format=\"%Y/%m/%d\").dt.year\n",
    "\n",
    "#Extracting month\n",
    "df[\"Journey_mon\"]=pd.to_datetime(df.Journey_date, format=\"%Y/%m/%d\").dt.month\n",
    "\n",
    "#Extracting day\n",
    "df[\"Journey_day\"]=pd.to_datetime(df.Journey_date, format=\"%Y/%m/%d\").dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d65bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking valuecount of Journey_year column\n",
    "\n",
    "df.Journey_year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661917d7",
   "metadata": {},
   "source": [
    " - Since all the entries in Journey_year column are same let's drop as it will not help in our core analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6ef63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping Journey_year column\n",
    "\n",
    "df = df.drop([\"Journey_year\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bbfd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking valuecount of Journey_mon column\n",
    "\n",
    "df.Journey_mon.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f765175c",
   "metadata": {},
   "source": [
    " - Since all the entries in Journey_mon column are same let's drop as it will not help in our core analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping Journey_mon column\n",
    "\n",
    "df = df.drop([\"Journey_mon\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aa01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking valuecount of Journey_year column\n",
    "\n",
    "df.Journey_day.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc894620",
   "metadata": {},
   "source": [
    " - Now Journey_day is ready for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ba389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping Journey_date column\n",
    "\n",
    "df = df.drop([\"Journey_date\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d5d82",
   "metadata": {},
   "source": [
    " - Dropping Journey_date column after extracting required information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be62393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting object data type to datetime \n",
    "\n",
    "df['Dtime'] =  pd.to_datetime(df['Dtime'])\n",
    "\n",
    "df['Atime'] =  pd.to_datetime(df['Atime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4defaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the data types of all columns again\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9363f3",
   "metadata": {},
   "source": [
    " - The data type has changed now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31e3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting hours and minutes from Dtime\n",
    "\n",
    "#Extracting Hours\n",
    "df[\"Dhour\"]=pd.to_datetime(df[\"Dtime\"]).dt.hour\n",
    "\n",
    "#Extracting Hours\n",
    "df[\"DMin\"]=pd.to_datetime(df[\"Dtime\"]).dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e9a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping Dep_Time column after extraction\n",
    "\n",
    "df = df.drop([\"Dtime\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044fac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting hours and minutes from Arrival_Time\n",
    "\n",
    "#Extracting Hours\n",
    "df[\"AHour\"]=pd.to_datetime(df[\"Atime\"]).dt.hour\n",
    "\n",
    "#Extracting Hours\n",
    "df[\"AMin\"]=pd.to_datetime(df[\"Atime\"]).dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72831dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping Arrival_Time column after extraction\n",
    "\n",
    "df = df.drop([\"Atime\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd71052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the data types of all columns again\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c9844f",
   "metadata": {},
   "source": [
    " - This is the datatypes after extraction and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f8926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking description of data set\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005955c5",
   "metadata": {},
   "source": [
    "### Above is the statistics about the dataset. The mean and the 2nd quantile values are almost same so there is no extreme outliers in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e92ec8",
   "metadata": {},
   "source": [
    "# Visualization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939531b0",
   "metadata": {},
   "source": [
    "### Univariate Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1eca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for categorical columns\n",
    "\n",
    "categorical_columns=[]\n",
    "for i in df.dtypes.index:\n",
    "    if df.dtypes[i]=='object':\n",
    "        categorical_columns.append(i)\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc5636",
   "metadata": {},
   "source": [
    " - Above are the categorical columns in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552b8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now checking for numerical columns\n",
    "\n",
    "numerical_columns=[]\n",
    "for i in df.dtypes.index:\n",
    "    if df.dtypes[i]!='object':\n",
    "        numerical_columns.append(i)\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b91b25",
   "metadata": {},
   "source": [
    " - Above are the numerical columns in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32afcb61",
   "metadata": {},
   "source": [
    "## Univariate analysis for numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc176a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution plot for all numerical columns\n",
    "\n",
    "plt.figure(figsize = (30,16))\n",
    "plotnumber = 1\n",
    "for column in df[numerical_columns]:\n",
    "    if plotnumber <=9:\n",
    "        ax = plt.subplot(3,3,plotnumber)\n",
    "        sns.distplot(df[column])\n",
    "        plt.xlabel(column,fontsize = 25)\n",
    "        plt.ylabel('Density',fontsize = 25)\n",
    "        plt.xticks(fontsize=20)  \n",
    "        plt.yticks(fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f6292",
   "metadata": {},
   "source": [
    "- There is no skewness in any of the numerical columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e831b",
   "metadata": {},
   "source": [
    "## Univariate Analysis for categorical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544c21b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar plot for all Categorical columns\n",
    "\n",
    "plt.figure(figsize = (30,10))\n",
    "plotnumber = 1\n",
    "for column in df[categorical_columns]:\n",
    "    if plotnumber <=3:\n",
    "        ax = plt.subplot(1,3,plotnumber)\n",
    "        sns.countplot(df[column])\n",
    "        plt.xlabel(column,fontsize = 25)\n",
    "        plt.ylabel('Count',fontsize = 25)\n",
    "        plt.xticks(rotation=90,fontsize=20)  \n",
    "        plt.yticks(fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe8090",
   "metadata": {},
   "source": [
    " - Indigo has maximum count which means most of the passengers preferred Indigo for there travelling.\n",
    "\n",
    "    \n",
    " - New Delhi has maximum count for source which means maximum passengers are choosing New Delhi as there source.\n",
    "\n",
    "\n",
    " - New Delhi has maximum count for Destination which means maximum passengers are choosing New Delhi as there Destination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765eae97",
   "metadata": {},
   "source": [
    "# Bivariate Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f82da",
   "metadata": {},
   "outputs": [],
   "source": [
    "col=['Stops', 'Journey_day', 'Dhour', 'DMin', 'AHour', 'AMin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbf601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stripplot for numerical columns\n",
    "\n",
    "plt.figure(figsize=(40,40))\n",
    "for i in range(len(col)):\n",
    "    plt.subplot(4,2,i+1)\n",
    "    sns.stripplot(x=df[col[i]] , y=df['Price'])\n",
    "    plt.title(f\"Price VS {col[i]}\",fontsize=40)\n",
    "    plt.xticks(fontsize=25)  \n",
    "    plt.yticks(fontsize=25)\n",
    "    plt.xlabel(col[i],fontsize = 30)\n",
    "    plt.ylabel('Price',fontsize = 30)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50fccd9",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    " - Flights with 2 stops costs more price compared to other flights.\n",
    "\n",
    "\n",
    " - In all the dates the price is almost same.\n",
    "\n",
    "\n",
    " - At 2PM departure time of every day the flight prices are high so it looks good to book flights rather than this departure time.\n",
    "\n",
    "\n",
    " - And Departure minute has less relation with target price.\n",
    "\n",
    "\n",
    " - At 7AM to 1PM Arrival time of every day the flight prices are high so it looks good to book flights rather than this arrival time.\n",
    "\n",
    "\n",
    " - And Arrival minute has less relation with target price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1806429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar plot for all categorical columns\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for i in range(len(categorical_columns)):\n",
    "    plt.subplot(3,2,i+1)\n",
    "    sns.barplot(y=df['Price'],x=df[categorical_columns[i]])\n",
    "    plt.title(f\"Price VS {categorical_columns[i]}\",fontsize=25)\n",
    "    plt.xticks(rotation=90,fontsize=15)  \n",
    "    plt.yticks(rotation=0,fontsize=15)\n",
    "    plt.xlabel(categorical_columns[i],fontsize = 20)\n",
    "    plt.ylabel('Price',fontsize = 20)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc6aea1",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    " - For Multiple Airlines the Price is high compared to other Airlines.\n",
    "\n",
    "\n",
    " - Taking Tirupati as Source costs highest Price Compared to other Source points.\n",
    "\n",
    "    \n",
    " - Taking Tirupati as Destination costs highest Price Compared to other Destination points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25c72de",
   "metadata": {},
   "source": [
    "# Multivariate Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03be310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair ploting for df\n",
    "\n",
    "sns.pairplot(df,hue=\"Price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3e7c2",
   "metadata": {},
   "source": [
    " - Above are the pair plots of each pair of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4244a",
   "metadata": {},
   "source": [
    "# Checking for outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0851af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the outliers using boxplot\n",
    "\n",
    "plt.figure(figsize=(30,15),facecolor='white')\n",
    "plotnumber=1\n",
    "for column in numerical_columns:\n",
    "    if plotnumber<=9:\n",
    "        ax=plt.subplot(3,3,plotnumber)\n",
    "        sns.boxplot(df[column],color='gold')\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25680830",
   "metadata": {},
   "source": [
    "### There are outliers in\n",
    "\n",
    " - Stops\n",
    " - Price\n",
    "\n",
    "Since Price is our target so we should not remove outliers from this column. And Stops is a categorical column So we should not remove outliers here also."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc8143c",
   "metadata": {},
   "source": [
    "# Checking for skewness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f69d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for skewness\n",
    "\n",
    "df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343c7382",
   "metadata": {},
   "source": [
    " - There is skewness in Stops and Price. Since Price is our target that's why we are not removing skewness here because we don't want our target to get manupulated. And Stops is categorical column so we are not removing skewness here also."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f724f",
   "metadata": {},
   "source": [
    "# Label Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404a9930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating categorical columns in df_1\n",
    "\n",
    "cat_col=[]\n",
    "for i in df.dtypes.index:\n",
    "    if df.dtypes[i]=='object':\n",
    "        cat_col.append(i)\n",
    "print(cat_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e35fc",
   "metadata": {},
   "source": [
    " - Above are the list of categorical columns in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c040b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE=LabelEncoder()\n",
    "df[cat_col]= df[cat_col].apply(LE.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021bef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5e8bbe",
   "metadata": {},
   "source": [
    " - Using label encoder i have encoded the categorical columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260a69c",
   "metadata": {},
   "source": [
    "# Checking correlation using heat map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b5734",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor=df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95665382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking correlation\n",
    "\n",
    "cor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9e97f3",
   "metadata": {},
   "source": [
    " - Above are the correlations of all the pair of features. To get better visualization on the correlation of features, let's plot it using heat map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b951d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the correlation matrix by plotting heat map.\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df.corr(),linewidths=.1,vmin=-1, vmax=1, fmt='.1g', annot = True, linecolor=\"black\",annot_kws={'size':10},cmap=\"coolwarm\")\n",
    "plt.yticks(rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0f8155",
   "metadata": {},
   "source": [
    " - There is no multicolinearity issue in any features.\n",
    "\n",
    "    \n",
    " - AMin is very less correlated with target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85218679",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "df.corr()['Price'].sort_values(ascending=False).drop(['Price']).plot(kind='bar',color='g')\n",
    "plt.xlabel('Feature',fontsize=14)\n",
    "plt.ylabel('column with target names',fontsize=14)\n",
    "plt.title('correlation',fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b1d21f",
   "metadata": {},
   "source": [
    " - AMin is very less correlated with target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c9f0f",
   "metadata": {},
   "source": [
    "# Separating features and label in train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f65acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(\"Price\",axis=1)\n",
    "y = df[\"Price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832f9dc6",
   "metadata": {},
   "source": [
    " - Here we have separated our target and independent columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31562b0f",
   "metadata": {},
   "source": [
    "# Scaling the data using standard scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb62938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(x), columns=x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b654190",
   "metadata": {},
   "source": [
    " - We have scaled our data using standard scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07884147",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8b52b6",
   "metadata": {},
   "source": [
    " - This is the data of independent variables after scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b92aeba",
   "metadata": {},
   "source": [
    "# Checking for multicolinearity issue using VIF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8661540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif=pd.DataFrame()\n",
    "vif[\"vif_Features\"]=[variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"Features\"]=X.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742f7115",
   "metadata": {},
   "source": [
    " - There is no multicolinearity issue in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd8fdc",
   "metadata": {},
   "source": [
    "# Finding Best Random State and Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42756c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "maxAccu=0\n",
    "maxRS=0\n",
    "for i in range(1,200):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.30, random_state =i)\n",
    "    mod = RandomForestRegressor()\n",
    "    mod.fit(X_train, y_train)\n",
    "    pred = mod.predict(X_test)\n",
    "    acc=r2_score(y_test, pred)\n",
    "    if acc>maxAccu:\n",
    "        maxAccu=acc\n",
    "        maxRS=i\n",
    "print(\"Best accuracy is \",maxAccu,\" on Random_state \",maxRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c67fb7",
   "metadata": {},
   "source": [
    "### We got the best accuracy and random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a77a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30,random_state=maxRS)  #Created train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b20f07c",
   "metadata": {},
   "source": [
    "# Regression Algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d54da0",
   "metadata": {},
   "source": [
    "## i) RandomForestRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f942229",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR=RandomForestRegressor()\n",
    "RFR.fit(X_train,y_train)\n",
    "pred=RFR.predict(X_test)\n",
    "R2_score = r2_score(y_test,pred)*100\n",
    "print('R2_score:',R2_score)\n",
    "print('mean_squared_error:',metrics.mean_squared_error(y_test,pred))\n",
    "print('mean_absolute_error:',metrics.mean_absolute_error(y_test,pred))\n",
    "print('root_mean_squared_error:',np.sqrt(metrics.mean_squared_error(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05c0bc2",
   "metadata": {},
   "source": [
    " - RFR is giving me 80.26% r2_score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7195ce24",
   "metadata": {},
   "source": [
    "## ii) XGB Regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ceff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB=XGBRegressor()\n",
    "XGB.fit(X_train,y_train)\n",
    "pred=XGB.predict(X_test)\n",
    "R2_score = r2_score(y_test,pred)*100\n",
    "print('R2_score:',R2_score)\n",
    "print('mean_squared_error:',metrics.mean_squared_error(y_test,pred))\n",
    "print('mean_absolute_error:',metrics.mean_absolute_error(y_test,pred))\n",
    "print('root_mean_squared_error:',np.sqrt(metrics.mean_squared_error(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188e3c1e",
   "metadata": {},
   "source": [
    " - XGB is giving me 79.56% r2_score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d64f0e",
   "metadata": {},
   "source": [
    "## iii) ExtraTreeRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb05422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETR=ExtraTreesRegressor()\n",
    "ETR.fit(X_train,y_train)\n",
    "pred=ETR.predict(X_test)\n",
    "print('R2_score:',r2_score(y_test,pred))\n",
    "print('mean_squared_error:',metrics.mean_squared_error(y_test,pred))\n",
    "print('mean_absolute_error:',metrics.mean_absolute_error(y_test,pred))\n",
    "print('root_mean_squared_error:',np.sqrt(metrics.mean_squared_error(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f6b06f",
   "metadata": {},
   "source": [
    " - ETR is giving me 81.13% r2_score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d1da0",
   "metadata": {},
   "source": [
    "## iv) Gradient Boosting Regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90de8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR=GradientBoostingRegressor()\n",
    "GBR.fit(X_train,y_train)\n",
    "pred=GBR.predict(X_test)\n",
    "print('R2_score:',r2_score(y_test,pred))\n",
    "print('mean_squared_error:',metrics.mean_squared_error(y_test,pred))\n",
    "print('mean_absolute_error:',metrics.mean_absolute_error(y_test,pred))\n",
    "print('root_mean_squared_error:',np.sqrt(metrics.mean_squared_error(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590a0f2a",
   "metadata": {},
   "source": [
    " - GBR is giving me 65.71% r2_score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027d4deb",
   "metadata": {},
   "source": [
    "## v) DecisionTreeRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTR=DecisionTreeRegressor()\n",
    "DTR.fit(X_train,y_train)\n",
    "pred=DTR.predict(X_test)\n",
    "print('R2_score:',r2_score(y_test,pred))\n",
    "print('mean_squared_error:',metrics.mean_squared_error(y_test,pred))\n",
    "print('mean_absolute_error:',metrics.mean_absolute_error(y_test,pred))\n",
    "print('root_mean_squared_error:',np.sqrt(metrics.mean_squared_error(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a32a50f",
   "metadata": {},
   "source": [
    " - DTR is giving me 64.55% r2_score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c10799",
   "metadata": {},
   "source": [
    "## vi) KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821872ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNN()\n",
    "knn.fit(X_train,y_train)\n",
    "pred=knn.predict(X_test)\n",
    "print('R2_score:',r2_score(y_test,pred))\n",
    "print('mean_squared_error:',metrics.mean_squared_error(y_test,pred))\n",
    "print('mean_absolute_error:',metrics.mean_absolute_error(y_test,pred))\n",
    "print('root_mean_squared_error:',np.sqrt(metrics.mean_squared_error(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b399a2",
   "metadata": {},
   "source": [
    " - KNN is giving me 53.35% r2_score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d6138f",
   "metadata": {},
   "source": [
    "## vii) Bagging Regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e325459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BG=BaggingRegressor()\n",
    "BG.fit(X_train,y_train)\n",
    "pred=BG.predict(X_test)\n",
    "print('R2_score:',r2_score(y_test,pred))\n",
    "print('mean_squared_error:',metrics.mean_squared_error(y_test,pred))\n",
    "print('mean_absolute_error:',metrics.mean_absolute_error(y_test,pred))\n",
    "print('root_mean_squared_error:',np.sqrt(metrics.mean_squared_error(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fdb5b7",
   "metadata": {},
   "source": [
    " - Bagging Regressor is giving me 79.32% r2_score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7071251",
   "metadata": {},
   "source": [
    "By looking into the model r2_score and error i found ExtraTreesRegressor as the best model with highest r2_score and least errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264d3c9d",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8cff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f50055",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = {'max_features':['auto','sqrt','log2'],\n",
    "             'min_samples_split':[1,2,3,4],\n",
    "             'n_estimators':[20,40,60,80,100],\n",
    "             'min_samples_leaf':[1,2,3,4,5],\n",
    "              'n_jobs':[-2,-1,1,2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c7e98",
   "metadata": {},
   "source": [
    " - Giving ETR parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa3409",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV=GridSearchCV(ExtraTreesRegressor(),parameter,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34e94ce",
   "metadata": {},
   "source": [
    " - Running grid search CV for ETR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fae70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de079ed7",
   "metadata": {},
   "source": [
    " - Tunning the model using GCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4e7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23948753",
   "metadata": {},
   "source": [
    " - Got the best parameters for ETR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_mod=ExtraTreesRegressor(max_features='auto',min_samples_leaf=2,min_samples_split=2,n_estimators=80,n_jobs=1)\n",
    "Best_mod.fit(X_train,y_train)\n",
    "pred=Best_mod.predict(X_test)\n",
    "print('R2_Score:',r2_score(y_test,pred)*100)\n",
    "print('mean_squared_error:',metrics.mean_squared_error(y_test,pred))\n",
    "print('mean_absolute_error:',metrics.mean_absolute_error(y_test,pred))\n",
    "print(\"RMSE value:\",np.sqrt(metrics.mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db54e1",
   "metadata": {},
   "source": [
    "### This is our model after tuning. We got 82.01% as r2_score before it was 81.18% which means accuracy has increased which is good!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae8337",
   "metadata": {},
   "source": [
    "# Saving the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model using .pkl\n",
    "\n",
    "import joblib\n",
    "joblib.dump(Best_mod,\"Flight_Price.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91216cc9",
   "metadata": {},
   "source": [
    " - We have saved our model as Flight_Price using .pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727f5040",
   "metadata": {},
   "source": [
    "## Predicting Flight Price for test dataset using Saved model of trained dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc352f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "model=joblib.load(\"Flight_Price.pkl\")\n",
    "\n",
    "#Prediction\n",
    "prediction = model.predict(X_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf6bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([model.predict(X_test)[:],y_test[:]],index=[\"Predicted\",\"Actual\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4395d8",
   "metadata": {},
   "source": [
    " - Above are the predicted values and the actual values. They are almost similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afae2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_test, prediction, c='crimson')\n",
    "p1 = max(max(prediction), max(y_test))\n",
    "p2 = min(min(prediction), min(y_test))\n",
    "plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "plt.xlabel('Actual', fontsize=15)\n",
    "plt.ylabel('Predicted', fontsize=15)\n",
    "plt.title(\"ExtraTreesRegressor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f10539a",
   "metadata": {},
   "source": [
    " - Plotting Actual vs Predicted, To get better insight. Blue line is the actual line and red dots are the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64cdcca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
